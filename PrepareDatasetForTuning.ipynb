{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Prepare avatar dataset for tuning ImageBindLora model\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare clips dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_text_labels(ds):\n",
    "    \n",
    "    gender_map = {\n",
    "              'Arvid': 'man', \n",
    "              'Bizdev': 'man',\n",
    "              'C9175': 'man',\n",
    "              'C9176': 'woman',\n",
    "              'C9180': 'woman',\n",
    "              'C9183': 'man',\n",
    "              'C9186': 'man',\n",
    "              'C9187': 'woman',\n",
    "              'C9188': 'man',\n",
    "              'Jessica': 'woman',\n",
    "              'Mia': 'woman',\n",
    "              'Nick': 'man',\n",
    "              'Vlad': 'man',\n",
    "              'Yao': 'man',\n",
    "              }\n",
    "    \n",
    "    ds['gender'] = ds.folder.apply(lambda x: gender_map[x])\n",
    "    ds['vcls'] = ds.vcls.apply(lambda x: x.replace('_', ' ').strip())\n",
    "    ds['vcls'] = ds.vcls.apply(lambda x: re.sub('talk ', 'talking ', x))\n",
    "    ds.loc[ds.vcls == 'pause', 'vcls'] = 'talk pause'\n",
    "    ds.loc[ds.vcls == 'yes', 'vcls'] = 'agreement'\n",
    "    ds.loc[ds.vcls == 'ok', 'vcls'] = 'agreement'\n",
    "\n",
    "    def get_sentence(r):\n",
    "        return f\"{r[0]} {r[1]}\"\n",
    "    \n",
    "    ds['sentence'] = ds[['gender', 'vcls']].apply(get_sentence, axis=1)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_105341/2089539814.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return f\"{r[0]} {r[1]}\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>folder</th>\n",
       "      <th>video_type</th>\n",
       "      <th>duration</th>\n",
       "      <th>vcls</th>\n",
       "      <th>gender</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C9180/videos/talk01.mp4</td>\n",
       "      <td>C9180</td>\n",
       "      <td>talk01</td>\n",
       "      <td>4.56</td>\n",
       "      <td>talk</td>\n",
       "      <td>woman</td>\n",
       "      <td>woman talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C9180/videos/talk02.mp4</td>\n",
       "      <td>C9180</td>\n",
       "      <td>talk02</td>\n",
       "      <td>3.80</td>\n",
       "      <td>talk</td>\n",
       "      <td>woman</td>\n",
       "      <td>woman talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C9180/videos/talk03.mp4</td>\n",
       "      <td>C9180</td>\n",
       "      <td>talk03</td>\n",
       "      <td>5.16</td>\n",
       "      <td>talk</td>\n",
       "      <td>woman</td>\n",
       "      <td>woman talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C9180/videos/talk04.mp4</td>\n",
       "      <td>C9180</td>\n",
       "      <td>talk04</td>\n",
       "      <td>2.08</td>\n",
       "      <td>talk</td>\n",
       "      <td>woman</td>\n",
       "      <td>woman talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C9180/videos/talk05.mp4</td>\n",
       "      <td>C9180</td>\n",
       "      <td>talk05</td>\n",
       "      <td>2.40</td>\n",
       "      <td>talk</td>\n",
       "      <td>woman</td>\n",
       "      <td>woman talk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      path folder video_type  duration  vcls gender  \\\n",
       "0  C9180/videos/talk01.mp4  C9180     talk01      4.56  talk  woman   \n",
       "1  C9180/videos/talk02.mp4  C9180     talk02      3.80  talk  woman   \n",
       "2  C9180/videos/talk03.mp4  C9180     talk03      5.16  talk  woman   \n",
       "3  C9180/videos/talk04.mp4  C9180     talk04      2.08  talk  woman   \n",
       "4  C9180/videos/talk05.mp4  C9180     talk05      2.40  talk  woman   \n",
       "\n",
       "     sentence  \n",
       "0  woman talk  \n",
       "1  woman talk  \n",
       "2  woman talk  \n",
       "3  woman talk  \n",
       "4  woman talk  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base = '/home/vash/apps/avatar/avatar_studio/db'\n",
    "df = pd.read_csv('/home/vash/apps/avatar/gesture_clustering/avatar_ds.csv')\n",
    "\n",
    "# some clips are broken and we need renove them from dataset\n",
    "with open('/home/vash/apps/avatar/original_imagebind/ImageBind/avatar_original.pickl', 'rb') as f:\n",
    "    labels = pickle.load(f)\n",
    "\n",
    "ds = pd.DataFrame()\n",
    "ds['path'] = labels\n",
    "ds = ds.merge(df, on='path', how='left')\n",
    "ds = preproc_text_labels(ds)\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence\n",
       "man talk                       86\n",
       "woman talk                     56\n",
       "man talking neutral            41\n",
       "man talking happy              25\n",
       "man general                    17\n",
       "man talking persuasive         14\n",
       "man talking interrogative      13\n",
       "woman talking neutral          10\n",
       "man talking sorry               8\n",
       "woman general                   8\n",
       "man affirmative                 6\n",
       "woman affirmative               6\n",
       "woman talking happy             5\n",
       "man talk pause                  5\n",
       "man negative                    5\n",
       "woman talking sorry             3\n",
       "woman negative                  3\n",
       "woman talking interrogative     3\n",
       "woman talk pause                2\n",
       "woman talking persuasive        2\n",
       "woman hands                     1\n",
       "woman cross                     1\n",
       "man agreement                   1\n",
       "man helpless                    1\n",
       "woman shy                       1\n",
       "woman dance                     1\n",
       "woman agreement                 1\n",
       "man sorry                       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.sentence.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepa key points for clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read points info for Avatar Dataset\n",
    "\n",
    "with open('/home/vash/apps/avatar/mmpose/wholebody_points_scaled.pckl', 'rb') as f:\n",
    "    points = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preprocessing foi ImageBind model like IMU input\n",
    "\n",
    "key_point_ids = [0,1,2,3,4,5,6,7,8,9,10,42,47,71,74,77]\n",
    "\n",
    "key_points_label_map = {\n",
    "    0: 'nose',\n",
    "    1: 'left_eye',\n",
    "    2: 'right_eye',\n",
    "    3: 'left_ear',\n",
    "    4: 'right_ear',\n",
    "    5: 'left_shoulder',\n",
    "    6: 'right_shoulder',\n",
    "    7: 'left_elbow',\n",
    "    8: 'right_elbow',\n",
    "    9: 'left_wrist',\n",
    "    10: 'right_wrist',\n",
    "    42: 'right_eyebrow',\n",
    "    47: 'left_eyebrow',\n",
    "    71: 'right_mouth',\n",
    "    74: 'center_mouth',\n",
    "    77: 'left_mouth'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>frame_id</th>\n",
       "      <th>point</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C9180/videos/talk01.mp4</td>\n",
       "      <td>0</td>\n",
       "      <td>nose</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>0.517443</td>\n",
       "      <td>0.241745</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C9180/videos/talk01.mp4</td>\n",
       "      <td>0</td>\n",
       "      <td>left_eye</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>0.568861</td>\n",
       "      <td>0.208983</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C9180/videos/talk01.mp4</td>\n",
       "      <td>0</td>\n",
       "      <td>right_eye</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>0.469996</td>\n",
       "      <td>0.205415</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C9180/videos/talk01.mp4</td>\n",
       "      <td>0</td>\n",
       "      <td>left_ear</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>0.624771</td>\n",
       "      <td>0.270560</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C9180/videos/talk01.mp4</td>\n",
       "      <td>0</td>\n",
       "      <td>right_ear</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>0.413557</td>\n",
       "      <td>0.260498</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     video  frame_id      point  height  width         x  \\\n",
       "0  C9180/videos/talk01.mp4         0       nose    1080   1080  0.517443   \n",
       "1  C9180/videos/talk01.mp4         0   left_eye    1080   1080  0.568861   \n",
       "2  C9180/videos/talk01.mp4         0  right_eye    1080   1080  0.469996   \n",
       "3  C9180/videos/talk01.mp4         0   left_ear    1080   1080  0.624771   \n",
       "4  C9180/videos/talk01.mp4         0  right_ear    1080   1080  0.413557   \n",
       "\n",
       "          y  scale  \n",
       "0  0.241745      2  \n",
       "1  0.208983      2  \n",
       "2  0.205415      2  \n",
       "3  0.270560      2  \n",
       "4  0.260498      2  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_ratio = 2\n",
    "\n",
    "l = []\n",
    "for p in points:\n",
    "    video = p['video']\n",
    "    frame_id = p['frame_id']\n",
    "    height = p['height']\n",
    "    width = p['width']\n",
    "    for p_id in key_point_ids:\n",
    "        x, y = p['kpts'][p_id]\n",
    "        l.append({'video': video, \n",
    "                  'frame_id': frame_id, \n",
    "                  'point': key_points_label_map[p_id],\n",
    "                  'height': height, \n",
    "                  'width': width, \n",
    "                  'x': x, \n",
    "                  'y': y,\n",
    "                  'scale': scale_ratio})\n",
    "        \n",
    "# Normalize coordinates\n",
    "points_df = pd.DataFrame(l)\n",
    "points_df['x'] = points_df['x'] / (points_df.width / scale_ratio)\n",
    "points_df['y'] = points_df['y'] / (points_df.height / scale_ratio)\n",
    "\n",
    "\n",
    "points_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>frame_id</th>\n",
       "      <th>point</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>scale</th>\n",
       "      <th>shift_x</th>\n",
       "      <th>shift_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>508190</th>\n",
       "      <td>Arvid/videos/talk_neutral_01.mp4</td>\n",
       "      <td>0</td>\n",
       "      <td>center_mouth</td>\n",
       "      <td>1080</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.494803</td>\n",
       "      <td>0.278039</td>\n",
       "      <td>2</td>\n",
       "      <td>0.495537</td>\n",
       "      <td>0.280426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508206</th>\n",
       "      <td>Arvid/videos/talk_neutral_01.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>center_mouth</td>\n",
       "      <td>1080</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.495537</td>\n",
       "      <td>0.280426</td>\n",
       "      <td>2</td>\n",
       "      <td>0.496552</td>\n",
       "      <td>0.282748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508222</th>\n",
       "      <td>Arvid/videos/talk_neutral_01.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>center_mouth</td>\n",
       "      <td>1080</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.496552</td>\n",
       "      <td>0.282748</td>\n",
       "      <td>2</td>\n",
       "      <td>0.502023</td>\n",
       "      <td>0.286497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508238</th>\n",
       "      <td>Arvid/videos/talk_neutral_01.mp4</td>\n",
       "      <td>3</td>\n",
       "      <td>center_mouth</td>\n",
       "      <td>1080</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.502023</td>\n",
       "      <td>0.286497</td>\n",
       "      <td>2</td>\n",
       "      <td>0.503274</td>\n",
       "      <td>0.286479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508254</th>\n",
       "      <td>Arvid/videos/talk_neutral_01.mp4</td>\n",
       "      <td>4</td>\n",
       "      <td>center_mouth</td>\n",
       "      <td>1080</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.503274</td>\n",
       "      <td>0.286479</td>\n",
       "      <td>2</td>\n",
       "      <td>0.507573</td>\n",
       "      <td>0.284855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   video  frame_id         point  height  \\\n",
       "508190  Arvid/videos/talk_neutral_01.mp4         0  center_mouth    1080   \n",
       "508206  Arvid/videos/talk_neutral_01.mp4         1  center_mouth    1080   \n",
       "508222  Arvid/videos/talk_neutral_01.mp4         2  center_mouth    1080   \n",
       "508238  Arvid/videos/talk_neutral_01.mp4         3  center_mouth    1080   \n",
       "508254  Arvid/videos/talk_neutral_01.mp4         4  center_mouth    1080   \n",
       "\n",
       "        width         x         y  scale   shift_x   shift_y  \n",
       "508190   1500  0.494803  0.278039      2  0.495537  0.280426  \n",
       "508206   1500  0.495537  0.280426      2  0.496552  0.282748  \n",
       "508222   1500  0.496552  0.282748      2  0.502023  0.286497  \n",
       "508238   1500  0.502023  0.286497      2  0.503274  0.286479  \n",
       "508254   1500  0.503274  0.286479      2  0.507573  0.284855  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = []\n",
    "for video, video_df in points_df.groupby('video'):\n",
    "    for point, point_df in video_df.groupby('point'):\n",
    "        point_df = point_df.sort_values('frame_id')\n",
    "        point_df['shift_x'] = point_df.x.shift(-1)\n",
    "        point_df['shift_y'] = point_df.y.shift(-1)\n",
    "        point_df = point_df.dropna()\n",
    "        l.append(point_df)\n",
    "points_df = pd.concat(l)\n",
    "points_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_keypoints_dst = {}\n",
    "\n",
    "for video, video_df in points_df.groupby('video'):\n",
    "    M = []\n",
    "    for frame_id, frame_df in video_df.groupby('frame_id'):\n",
    "        frame_df = frame_df.sort_values('point')\n",
    "        # pairwise distances between key points on current frame\n",
    "        m = pairwise_distances(frame_df[['x', 'y']].values, frame_df[['x', 'y']].values)\n",
    "        # pairwise distances between key points on next frame\n",
    "        m_next = pairwise_distances(frame_df[['shift_x', 'shift_y']].values, frame_df[['shift_x', 'shift_y']].values)\n",
    "        \n",
    "        # delta\n",
    "        dm = m_next - m\n",
    "        # get upper triangle without diagonal # after that shape will be (120, 0)\n",
    "        tri_ids = np.triu_indices_from(dm, k=1)\n",
    "\n",
    "        M.append(dm[tri_ids])\n",
    "\n",
    "    M = np.vstack(M)\n",
    "    video_keypoints_dst[video] = np.vstack(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def points_to_imu(m):\n",
    "    \"\"\" IMU input for ImageBind model 6 x 2000\n",
    "        in this case I take into account first 4 seconds of video with fps 25 (4 * 25) and for convinience I get rid off last column(distances to right_wrist)\n",
    "    \"\"\"\n",
    "    n_rows = 100\n",
    "    _m = m[:n_rows] # !\n",
    "    dr = n_rows - len(_m)\n",
    "    b = torch.from_numpy(_m.astype('float32'))\n",
    "    if dr > 0:\n",
    "        b = torch.nn.functional.pad(b, (0, 0, 0, dr), mode='constant', value=0)\n",
    "    imu = torch.stack([b[:, :20].flatten(), b[:, 20:40].flatten(), b[:, 40:60].flatten(), b[:, 60:80].flatten(), b[:, 80:100].flatten(), b[:, 100:].flatten()])\n",
    "    return imu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 2000])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in video_keypoints_dst:\n",
    "    m = video_keypoints_dst[i]\n",
    "    imu = points_to_imu(m)\n",
    "\n",
    "    imu_batch  = torch.unsqueeze(imu, 0)\n",
    "    break\n",
    "imu_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cretae dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize all video with scale 0.5\n",
    "# Prepare csv with normalized keypoints distances(like imu modality)\n",
    "# Dataset structure: \"Actor\": \"Clips\", \"telemetry\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 326/326 [05:47<00:00,  1.07s/it]\n"
     ]
    }
   ],
   "source": [
    "ds_base = '/home/vash/apps/avatar/imu_ds'\n",
    "\n",
    "for i in tqdm(video_keypoints_dst):\n",
    "    actor = i.split('/')[0]\n",
    "    video =  i.split('/')[-1]\n",
    "    actor_path = os.path.join(ds_base, actor)\n",
    "    actor_clips = os.path.join(actor_path, 'clips')\n",
    "    actor_telemetry = os.path.join(actor_path, 'telemetry')\n",
    "    os.makedirs(actor_path, exist_ok=True)\n",
    "    os.makedirs(actor_clips, exist_ok=True)\n",
    "    os.makedirs(actor_telemetry, exist_ok=True)\n",
    "\n",
    "    m = video_keypoints_dst[i]\n",
    "    imu = points_to_imu(m)\n",
    "    torch.save(imu, os.path.join(actor_telemetry, video.replace('.mp4', '.pt')))\n",
    "\n",
    "    video_path = os.path.join(base, i)\n",
    "    out_video_path = os.path.join(actor_clips, video)\n",
    "\n",
    "    ! ffmpeg -i $video_path -vf scale=\"ceil(iw/4)*2:ceil(ih/4)*2\" $out_video_path -hide_banner -loglevel error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>folder</th>\n",
       "      <th>video_type</th>\n",
       "      <th>duration</th>\n",
       "      <th>vcls</th>\n",
       "      <th>gender</th>\n",
       "      <th>sentence</th>\n",
       "      <th>clip</th>\n",
       "      <th>telemetry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C9180/videos/talk01.mp4</td>\n",
       "      <td>C9180</td>\n",
       "      <td>talk01</td>\n",
       "      <td>4.56</td>\n",
       "      <td>talk</td>\n",
       "      <td>woman</td>\n",
       "      <td>woman_talk</td>\n",
       "      <td>C9180/clips/talk01.mp4</td>\n",
       "      <td>C9180/telemetry/talk01.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C9180/videos/talk02.mp4</td>\n",
       "      <td>C9180</td>\n",
       "      <td>talk02</td>\n",
       "      <td>3.80</td>\n",
       "      <td>talk</td>\n",
       "      <td>woman</td>\n",
       "      <td>woman_talk</td>\n",
       "      <td>C9180/clips/talk02.mp4</td>\n",
       "      <td>C9180/telemetry/talk02.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C9180/videos/talk03.mp4</td>\n",
       "      <td>C9180</td>\n",
       "      <td>talk03</td>\n",
       "      <td>5.16</td>\n",
       "      <td>talk</td>\n",
       "      <td>woman</td>\n",
       "      <td>woman_talk</td>\n",
       "      <td>C9180/clips/talk03.mp4</td>\n",
       "      <td>C9180/telemetry/talk03.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C9180/videos/talk04.mp4</td>\n",
       "      <td>C9180</td>\n",
       "      <td>talk04</td>\n",
       "      <td>2.08</td>\n",
       "      <td>talk</td>\n",
       "      <td>woman</td>\n",
       "      <td>woman_talk</td>\n",
       "      <td>C9180/clips/talk04.mp4</td>\n",
       "      <td>C9180/telemetry/talk04.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C9180/videos/talk05.mp4</td>\n",
       "      <td>C9180</td>\n",
       "      <td>talk05</td>\n",
       "      <td>2.40</td>\n",
       "      <td>talk</td>\n",
       "      <td>woman</td>\n",
       "      <td>woman_talk</td>\n",
       "      <td>C9180/clips/talk05.mp4</td>\n",
       "      <td>C9180/telemetry/talk05.pt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      path folder video_type  duration  vcls gender  \\\n",
       "0  C9180/videos/talk01.mp4  C9180     talk01      4.56  talk  woman   \n",
       "1  C9180/videos/talk02.mp4  C9180     talk02      3.80  talk  woman   \n",
       "2  C9180/videos/talk03.mp4  C9180     talk03      5.16  talk  woman   \n",
       "3  C9180/videos/talk04.mp4  C9180     talk04      2.08  talk  woman   \n",
       "4  C9180/videos/talk05.mp4  C9180     talk05      2.40  talk  woman   \n",
       "\n",
       "     sentence                    clip                  telemetry  \n",
       "0  woman_talk  C9180/clips/talk01.mp4  C9180/telemetry/talk01.pt  \n",
       "1  woman_talk  C9180/clips/talk02.mp4  C9180/telemetry/talk02.pt  \n",
       "2  woman_talk  C9180/clips/talk03.mp4  C9180/telemetry/talk03.pt  \n",
       "3  woman_talk  C9180/clips/talk04.mp4  C9180/telemetry/talk04.pt  \n",
       "4  woman_talk  C9180/clips/talk05.mp4  C9180/telemetry/talk05.pt  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare csv for avatar tuning dataset\n",
    "\n",
    "ds['sentence'] = ds['sentence'].str.replace(' ', '_')\n",
    "ds['clip'] = ds['path'].str.replace('videos', 'clips')\n",
    "ds['telemetry'] = ds['path'].str.replace('videos', 'telemetry')\n",
    "ds['telemetry'] = ds['telemetry'].str.replace('mp4', 'pt')\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.to_csv('avatar_tune_ds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>folder</th>\n",
       "      <th>video_type</th>\n",
       "      <th>duration</th>\n",
       "      <th>vcls</th>\n",
       "      <th>gender</th>\n",
       "      <th>sentence</th>\n",
       "      <th>clip</th>\n",
       "      <th>telemetry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C9180/videos/talk01.mp4</td>\n",
       "      <td>C9180</td>\n",
       "      <td>talk01</td>\n",
       "      <td>4.56</td>\n",
       "      <td>talk</td>\n",
       "      <td>woman</td>\n",
       "      <td>woman_talk</td>\n",
       "      <td>C9180/clips/talk01.mp4</td>\n",
       "      <td>C9180/telemetry/talk01.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C9180/videos/talk02.mp4</td>\n",
       "      <td>C9180</td>\n",
       "      <td>talk02</td>\n",
       "      <td>3.80</td>\n",
       "      <td>talk</td>\n",
       "      <td>woman</td>\n",
       "      <td>woman_talk</td>\n",
       "      <td>C9180/clips/talk02.mp4</td>\n",
       "      <td>C9180/telemetry/talk02.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C9180/videos/talk03.mp4</td>\n",
       "      <td>C9180</td>\n",
       "      <td>talk03</td>\n",
       "      <td>5.16</td>\n",
       "      <td>talk</td>\n",
       "      <td>woman</td>\n",
       "      <td>woman_talk</td>\n",
       "      <td>C9180/clips/talk03.mp4</td>\n",
       "      <td>C9180/telemetry/talk03.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C9180/videos/talk04.mp4</td>\n",
       "      <td>C9180</td>\n",
       "      <td>talk04</td>\n",
       "      <td>2.08</td>\n",
       "      <td>talk</td>\n",
       "      <td>woman</td>\n",
       "      <td>woman_talk</td>\n",
       "      <td>C9180/clips/talk04.mp4</td>\n",
       "      <td>C9180/telemetry/talk04.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C9180/videos/talk05.mp4</td>\n",
       "      <td>C9180</td>\n",
       "      <td>talk05</td>\n",
       "      <td>2.40</td>\n",
       "      <td>talk</td>\n",
       "      <td>woman</td>\n",
       "      <td>woman_talk</td>\n",
       "      <td>C9180/clips/talk05.mp4</td>\n",
       "      <td>C9180/telemetry/talk05.pt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      path folder video_type  duration  vcls gender  \\\n",
       "0  C9180/videos/talk01.mp4  C9180     talk01      4.56  talk  woman   \n",
       "1  C9180/videos/talk02.mp4  C9180     talk02      3.80  talk  woman   \n",
       "2  C9180/videos/talk03.mp4  C9180     talk03      5.16  talk  woman   \n",
       "3  C9180/videos/talk04.mp4  C9180     talk04      2.08  talk  woman   \n",
       "4  C9180/videos/talk05.mp4  C9180     talk05      2.40  talk  woman   \n",
       "\n",
       "     sentence                    clip                  telemetry  \n",
       "0  woman_talk  C9180/clips/talk01.mp4  C9180/telemetry/talk01.pt  \n",
       "1  woman_talk  C9180/clips/talk02.mp4  C9180/telemetry/talk02.pt  \n",
       "2  woman_talk  C9180/clips/talk03.mp4  C9180/telemetry/talk03.pt  \n",
       "3  woman_talk  C9180/clips/talk04.mp4  C9180/telemetry/talk04.pt  \n",
       "4  woman_talk  C9180/clips/talk05.mp4  C9180/telemetry/talk05.pt  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.load('/home/vash/apps/avatar/ImageBindLora_tuning/ImageBind-LoRA/.datasets/avatar/Arvid/telemetry/talk_neutral_05.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(a,np.ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ImageBind",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
